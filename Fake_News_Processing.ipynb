{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News_Processing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPR+1Odomh1swMNZzcVDeF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanleykywu/Facial_Hapiness_Sadness_Detection/blob/master/Fake_News_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2q6Glb-yaFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install Tensorflow\n",
        "#!pip install Keras\n",
        "#!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2COcEH54QlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W31zx90f3fBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words('english')\n",
        "\n",
        "def clean_string(str):\n",
        "  arr = np.array([word for word in str.split() if word not in stoplist])\n",
        "  y=\"\"\n",
        "  for i in range(arr.size):\n",
        "    y += arr[i] + \" \"\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQQ9BcEsQVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Fake_News_Language_Processing/Fake.csv\", usecols=['title'])\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "\n",
        "train_fake = np.array(df[msk])[:,0]\n",
        "train_fake_output = np.array([1 for i in range(train_fake.size)])\n",
        "test_fake = np.array(df[~msk])[:,0]\n",
        "test_fake_output = np.array([1 for i in range(test_fake.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnGiaLvHspoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Fake_News_Language_Processing/True.csv\", usecols=['title'])\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "train_true = np.array(df[msk])[:,0]\n",
        "train_true_output = np.array([0 for i in range(train_true.size)])\n",
        "test_true = np.array(df[~msk])[:,0]\n",
        "test_true_output = np.array([0 for i in range(test_true.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghSV6tt7ssO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_string = np.append(train_fake, train_true)\n",
        "train_output = np.append(train_fake_output, train_true_output)\n",
        "\n",
        "test_string = np.append(test_fake, test_true)\n",
        "test_output = np.append(test_fake_output, test_true_output)\n",
        "\n",
        "for i in range(train_string.size):\n",
        "  train_string[i] = clean_string(train_string[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uP8t5OF8sPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing String inputs by transforming them into integers \n",
        "# by using hashing_trick\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import hashing_trick\n",
        "\n",
        "length = 750\n",
        "\n",
        "train_data = np.array([np.array(hashing_trick(train_string[i], length)) for i in range(train_string.size)])\n",
        "test_data = np.array([np.array(hashing_trick(test_string[i], length)) for i in range(test_string.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LakQihl_EecN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flattened = np.hstack(train_data)\n",
        "most_freq = []\n",
        "for i in range(20):\n",
        "  counts = np.bincount(flattened)\n",
        "  max = np.argmax(counts)\n",
        "  # print(max)\n",
        "  most_freq.append(max)\n",
        "  x = np.array([flattened[i] != max for i in range(flattened.size)])\n",
        "  flattened = flattened[x]\n",
        "\n",
        "print(most_freq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RDAfUOcU_6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(train_data.size):\n",
        "  x = np.array([train_data[i][j] in most_freq for j in range(train_data[i].size)])\n",
        "  train_data[i] = train_data[i][x]\n",
        "\n",
        "resized_training = np.array([np.resize(np.asarray(train_data[i]), (5)) for i in range(train_data.size)])\n",
        "\n",
        "resized_training[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr5_O3dZzpPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(resized_training, train_output.T, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}